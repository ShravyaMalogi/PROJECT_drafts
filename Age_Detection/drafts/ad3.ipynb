{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "roizVSfk2KLP",
        "S-DjDdRYvwEu"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShravyaMalogi/PROJECT_drafts/blob/main/Age_Detection/ad3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "roizVSfk2KLP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41b1boYMWT1B",
        "outputId": "35b0b8ed-d4a2-4c63-ca2c-8a7800ecd0b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/MyDrive/projects/datasets/\""
      ],
      "metadata": {
        "id": "DeScvnt1Cjgl",
        "outputId": "9685bc9e-2a9f-498b-ba05-b46c472a9ca1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age_detection_model.h5\timdb_train_new.csv  imdbwiki.zip\n",
            "imdb_test_new.csv\timdb_valid_new.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "bad_files = []\n",
        "\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/projects/datasets/imdbwiki.zip', 'r') as zipf:\n",
        "    for file in zipf.filelist:\n",
        "        try:\n",
        "            zipf.open(file.filename).read()\n",
        "        except:\n",
        "            bad_files.append(file.filename)\n",
        "\n",
        "print(\"🛑 Corrupted files found:\")\n",
        "for bf in bad_files:\n",
        "    print(bf)"
      ],
      "metadata": {
        "id": "Eci5qOK0njv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "f96f90b6-5fb8-47ec-a99c-15530b7f56af"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🛑 Corrupted files found:\n",
            "imdb-clean-1024/imdb-clean-1024/22/nm0266422_rm3838610432_1974-9-19_2005.jpg\n",
            "imdb-clean-1024/imdb-clean-1024/24/nm1861624_rm3706501120_1982-11-15_2010.jpg\n",
            "imdb-clean-1024/imdb-clean-1024/25/nm1553725_rm2946674688_1985-3-15_2011.jpg\n",
            "imdb-clean-1024/imdb-clean-1024/41/nm0266441_rm2134412800_1961-5-13_1994.jpg\n",
            "imdb-clean-1024/imdb-clean-1024/43/nm0001743_rm2994522112_1948-1-29_1984.jpg\n",
            "imdb-clean-1024/imdb-clean-1024/73/nm0001173_rm2329378816_1968-3-12_2008.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the zip file on your Google Drive\n",
        "zip_path = '/content/drive/MyDrive/projects/datasets/imdbwiki.zip'  # change this\n",
        "extract_path = '/content/imdb-wiki_data'\n",
        "\n",
        "# List of corrupted files inside the ZIP to skip\n",
        "corrupted_files = bad_files\n",
        "\n",
        "# Extract all except corrupted files\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    for file in zip_ref.namelist():\n",
        "        if file not in corrupted_files:\n",
        "            try:\n",
        "                zip_ref.extract(file, extract_path)\n",
        "            except Exception as e:\n",
        "                print(f\"Error extracting {file}: {e}\")\n",
        "        else:\n",
        "            print(f\"Skipping corrupted file: {file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dceCxuHctXhy",
        "outputId": "a18e9e5e-b1eb-4863-c045-deebb7c36033",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping corrupted file: imdb-clean-1024/imdb-clean-1024/22/nm0266422_rm3838610432_1974-9-19_2005.jpg\n",
            "Skipping corrupted file: imdb-clean-1024/imdb-clean-1024/24/nm1861624_rm3706501120_1982-11-15_2010.jpg\n",
            "Skipping corrupted file: imdb-clean-1024/imdb-clean-1024/25/nm1553725_rm2946674688_1985-3-15_2011.jpg\n",
            "Skipping corrupted file: imdb-clean-1024/imdb-clean-1024/41/nm0266441_rm2134412800_1961-5-13_1994.jpg\n",
            "Skipping corrupted file: imdb-clean-1024/imdb-clean-1024/43/nm0001743_rm2994522112_1948-1-29_1984.jpg\n",
            "Skipping corrupted file: imdb-clean-1024/imdb-clean-1024/73/nm0001173_rm2329378816_1968-3-12_2008.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CODE"
      ],
      "metadata": {
        "id": "GJ5yJaHneP75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Imports and Setup\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import mixed_precision\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Step 2: Set mixed precision for speed (T4 GPU)\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Step 3: Load CSVs (adjust paths if needed)\n",
        "train_df = pd.read_csv('/content/imdb-wiki_data/imdb_train_new_1024.csv')\n",
        "val_df = pd.read_csv('/content/imdb-wiki_data/imdb_valid_new_1024.csv')\n",
        "test_df = pd.read_csv('/content/imdb-wiki_data/imdb_test_new_1024.csv')\n",
        "\n",
        "# Normalize age (keep range small for MSE loss)\n",
        "train_df['age'] = train_df['age'] / 100.0\n",
        "val_df['age'] = val_df['age'] / 100.0\n",
        "test_df['age'] = test_df['age'] / 100.0\n",
        "\n",
        "# Step 4: Define parameters\n",
        "image_size = 224  # Try 160 for faster training\n",
        "batch_size = 32   # Increase if no OOM (64 max on T4 usually)\n",
        "epochs = 15\n",
        "\n",
        "# Step 5: Data generators\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_gen = datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory='/content/imdb-wiki_data/imdb-clean-1024/imdb-clean-1024',\n",
        "    x_col='filename',\n",
        "    y_col='age',\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='raw'\n",
        ")\n",
        "\n",
        "val_gen = datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    directory='/content/imdb-wiki_data/imdb-clean-1024/imdb-clean-1024',\n",
        "    x_col='filename',\n",
        "    y_col='age',\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='raw'\n",
        ")\n",
        "\n",
        "# Step 6: Build model\n",
        "base_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=(image_size, image_size, 3))\n",
        "base_model.trainable = False  # Freeze for speed\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(1, dtype='float32')  # force output to float32 (important for mixed precision)\n",
        "])\n",
        "\n",
        "# Step 7: Compile\n",
        "optimizer = Adam(learning_rate=1e-4)\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "\n",
        "# Step 8: Callbacks\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2)\n",
        "checkpoint = ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"val_loss\")\n",
        "\n",
        "# Step 9: Train\n",
        "model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=epochs,\n",
        "    callbacks=[early_stop, reduce_lr, checkpoint]\n",
        ")\n",
        "\n",
        "# Step 10: Prediction\n",
        "# You can multiply by 100 to get the real age back\n",
        "# predicted_age = model.predict(some_image_batch)[0] * 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdOy0FXceU-L",
        "outputId": "9639353f-3f89-48ed-a887-eb13850c4306"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 183884 validated image filenames.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 3 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 45972 validated image filenames.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m5747/5747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0411 - mae: 0.1360"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m5747/5747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m756s\u001b[0m 129ms/step - loss: 0.0411 - mae: 0.1360 - val_loss: 0.0121 - val_mae: 0.0855 - learning_rate: 1.0000e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m5747/5747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0129 - mae: 0.0885"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m5747/5747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m654s\u001b[0m 114ms/step - loss: 0.0129 - mae: 0.0885 - val_loss: 0.0115 - val_mae: 0.0834 - learning_rate: 1.0000e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m5747/5747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m680s\u001b[0m 114ms/step - loss: 0.0119 - mae: 0.0849 - val_loss: 0.0116 - val_mae: 0.0833 - learning_rate: 1.0000e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m5747/5747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0114 - mae: 0.0834"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m5747/5747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m649s\u001b[0m 113ms/step - loss: 0.0114 - mae: 0.0834 - val_loss: 0.0115 - val_mae: 0.0826 - learning_rate: 1.0000e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m5747/5747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0112 - mae: 0.0826"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m5747/5747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m655s\u001b[0m 114ms/step - loss: 0.0112 - mae: 0.0826 - val_loss: 0.0112 - val_mae: 0.0828 - learning_rate: 5.0000e-05\n",
            "Epoch 6/15\n",
            "\u001b[1m5747/5747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0111 - mae: 0.0820"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5747/5747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m651s\u001b[0m 113ms/step - loss: 0.0111 - mae: 0.0820 - val_loss: 0.0111 - val_mae: 0.0822 - learning_rate: 5.0000e-05\n",
            "Epoch 7/15\n",
            "\u001b[1m5747/5747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m687s\u001b[0m 114ms/step - loss: 0.0110 - mae: 0.0817 - val_loss: 0.0111 - val_mae: 0.0822 - learning_rate: 5.0000e-05\n",
            "Epoch 8/15\n",
            "\u001b[1m5747/5747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0108 - mae: 0.0812"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m5747/5747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m681s\u001b[0m 118ms/step - loss: 0.0108 - mae: 0.0812 - val_loss: 0.0111 - val_mae: 0.0819 - learning_rate: 2.5000e-05\n",
            "Epoch 9/15\n",
            "\u001b[1m5747/5747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0107 - mae: 0.0807"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m5747/5747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m684s\u001b[0m 119ms/step - loss: 0.0107 - mae: 0.0807 - val_loss: 0.0111 - val_mae: 0.0822 - learning_rate: 2.5000e-05\n",
            "Epoch 10/15\n",
            "\u001b[1m5747/5747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0106 - mae: 0.0803"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m5747/5747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m677s\u001b[0m 118ms/step - loss: 0.0106 - mae: 0.0803 - val_loss: 0.0111 - val_mae: 0.0820 - learning_rate: 1.2500e-05\n",
            "Epoch 11/15\n",
            "\u001b[1m5747/5747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m686s\u001b[0m 119ms/step - loss: 0.0106 - mae: 0.0805 - val_loss: 0.0111 - val_mae: 0.0823 - learning_rate: 1.2500e-05\n",
            "Epoch 12/15\n",
            "\u001b[1m5747/5747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0105 - mae: 0.0801"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m5747/5747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m684s\u001b[0m 119ms/step - loss: 0.0105 - mae: 0.0801 - val_loss: 0.0111 - val_mae: 0.0821 - learning_rate: 6.2500e-06\n",
            "Epoch 13/15\n",
            "\u001b[1m3089/5747\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m4:02\u001b[0m 91ms/step - loss: 0.0106 - mae: 0.0802"
          ]
        }
      ]
    }
  ]
}
